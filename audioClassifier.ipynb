{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f95f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import soundfile as sf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d452b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "NORMALIZED_SAMPLINGRATE: int = 16000 # Hz\n",
    "FIXED_DURATION: float = 5.0 # Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1859955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_audio(folderPath: str, label: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    # List to store the audio data\n",
    "    audios: list = []\n",
    "    labels: list = []\n",
    "    # Loop through the audio files in the given folder\n",
    "    fileName: str\n",
    "    for fileName in os.listdir(folderPath):\n",
    "        # Path to the audio file\n",
    "        filePath: str = os.path.join(folderPath, fileName)\n",
    "\n",
    "        # Try to load the file, error just in case\n",
    "        try:\n",
    "            # Load the audio file\n",
    "            audio: np.ndarray\n",
    "            sr: int\n",
    "            audio, sr = sf.read(filePath)\n",
    "\n",
    "            # Resample if sampling rate is not 16000 as it should already be.\n",
    "            if sr != NORMALIZED_SAMPLINGRATE:\n",
    "                numSamples: int = int(len(audio) * NORMALIZED_SAMPLINGRATE / sr)\n",
    "                audio = signal.resample(audio, numSamples)\n",
    "                sr = NORMALIZED_SAMPLINGRATE\n",
    "\n",
    "            # Append the data as a dictionary\n",
    "            audios.append({\n",
    "                \"fileName\": fileName,\n",
    "                \"audio\": audio\n",
    "            })\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {fileName}: {e}\")\n",
    "\n",
    "    return audios, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3859d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio(audio: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    # Frequency normalization. Removing irrelevant frequencies using bandpass filter.\n",
    "    # Input the frequency range you want.\n",
    "\n",
    "    # values must be 0 < x < 8000.\n",
    "    audio = normalize_frequency(audio, 10, 7999)\n",
    "    # Samples need to have a fixed duration for ML classifier model.\n",
    "    audio = normalize_duration(audio, FIXED_DURATION, NORMALIZED_SAMPLINGRATE)\n",
    "\n",
    "    # Amplitude normalization by Peak Normalization. Normalized -1 to 1.\n",
    "    audio = normalize_amplitude(audio)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6a3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_amplitude(audio: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    # Take peak from every audio file and divide file by it.\n",
    "    audioData: dict\n",
    "    for audioData in audio:\n",
    "        peak: int = np.max(np.abs(audioData[\"audio\"]))\n",
    "\n",
    "        audioData[\"audio\"] = audioData[\"audio\"] / peak\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b37e25",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_frequency(audio: np.ndarray, lowcut: int, highcut: int,\n",
    "                         sr: int=NORMALIZED_SAMPLINGRATE) -> np.ndarray:\n",
    "\n",
    "    # Normalize frequency range to nyquist\n",
    "    nyquist: int = sr / 2\n",
    "    low: int = lowcut / nyquist\n",
    "    high: int = highcut / nyquist\n",
    "\n",
    "    # Remove unwanted frequencies with a bandpass filter\n",
    "    audioData: dict\n",
    "    for audioData in audio:\n",
    "        sos: np.ndarray = signal.butter(10, [low, high], btype='band', output='sos')\n",
    "        audioData[\"audio\"] = signal.sosfilt(sos, audioData[\"audio\"])\n",
    "\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f478bf32",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def normalize_duration(audio: np.ndarray, fixedDuration: float=FIXED_DURATION,\n",
    "                        samplingRate: int=NORMALIZED_SAMPLINGRATE) -> np.ndarray:\n",
    "    audioData: dict\n",
    "    for audioData in audio:\n",
    "        numSamples: int = int(fixedDuration * samplingRate)\n",
    "        audioLength: int = len(audioData[\"audio\"])\n",
    "        if audioLength > numSamples:\n",
    "            audioData[\"audio\"] = audioData[\"audio\"][:numSamples]\n",
    "        else:\n",
    "            padding = np.zeros(numSamples - len(audioData[\"audio\"]))\n",
    "            audioData[\"audio\"] = np.concatenate([audioData[\"audio\"], padding])\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9710fd47",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_features(audio: np.ndarray) -> np.ndarray:\n",
    "    allFeatures: list = []\n",
    "    audioData: dict\n",
    "    for audioData in audio:\n",
    "        audio = audioData[\"audio\"]\n",
    "        # Extract features\n",
    "        mfccs: np.ndarray = librosa.feature.mfcc(y=audio, sr=NORMALIZED_SAMPLINGRATE, n_mfcc=13)\n",
    "        delta: np.ndarray = librosa.feature.delta(mfccs)\n",
    "        delta2: np.ndarray = librosa.feature.delta(mfccs, order=2)\n",
    "        zcr: np.ndarray = librosa.feature.zero_crossing_rate(audio)\n",
    "        # Should we take the mean of the features to lower the dimensionality?\n",
    "        mfccsMean: np.ndarray = np.mean(mfccs.T, axis=0)\n",
    "        deltaMean: np.ndarray = np.mean(delta.T, axis=0)\n",
    "        delta2Mean: np.ndarray = np.mean(delta2.T, axis=0)\n",
    "        zcrMean: np.ndarray = np.mean(zcr.T, axis=0)\n",
    "        # Add concatenated features to the list of all features\n",
    "        allFeatures.append(np.hstack([mfccsMean.T, deltaMean.T, delta2Mean.T, zcrMean.T]).flatten())\n",
    "\n",
    "    sc: StandardScaler = StandardScaler()\n",
    "    scaledFeatures: np.ndarray = sc.fit_transform(allFeatures)\n",
    "    return np.array(scaledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21642175",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load training data\n",
    "    # For the sake of efficiency audio has been converted to .wav mono sound in advance.\n",
    "    # This way it does not need to be done every time the program is tested and takes a lot less disk space.\n",
    "    carAudio: np.ndarray\n",
    "    carLabels: np.ndarray\n",
    "    carAudio, carLabels = load_all_audio(\"carSamples\", 0)\n",
    "\n",
    "    tramAudio: np.ndarray\n",
    "    tram_labels: np.ndarray\n",
    "    tramAudio, tram_labels = load_all_audio(\"tramSamples\", 1)\n",
    "\n",
    "    # Normalize audio signals.\n",
    "    carAudio: np.ndarray = normalize_audio(carAudio)\n",
    "    tramAudio: np.ndarray = normalize_audio(tramAudio)\n",
    "    audioSamples: np.ndarray = np.concatenate((carAudio, tramAudio), axis=0)\n",
    "    yTrain: np.ndarray = np.concatenate((carLabels, tram_labels), axis=0)\n",
    "    # Extract features from audio samples.\n",
    "    xTrain: np.ndarray = extract_features(audioSamples)\n",
    "\n",
    "    # Do the same steps (load, normalization and feature extraction) for test data\n",
    "    carAudioTest: np.ndarray\n",
    "    carLabelsTest: np.ndarray\n",
    "    carAudioTest, carLabelsTest = load_all_audio(\"carTest\", 0)\n",
    "\n",
    "    tramAudioTest: np.ndarray\n",
    "    tram_labelsTest: np.ndarray\n",
    "    tramAudioTest, tram_labelsTest = load_all_audio(\"tramTest\", 1)\n",
    "\n",
    "    carAudioTest: np.ndarray = normalize_audio(carAudioTest)\n",
    "    tramAudioTest: np.ndarray = normalize_audio(tramAudioTest)\n",
    "    audioSamplesTest: np.ndarray = np.concatenate((carAudioTest, tramAudioTest), axis=0)\n",
    "    yTest: np.ndarray = np.concatenate((carLabelsTest, tram_labelsTest), axis=0)\n",
    "    xTest: np.ndarray = extract_features(audioSamplesTest)\n",
    "\n",
    "    # Train the model\n",
    "    clf: RandomForestClassifier = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    # Code used to validate the model:\n",
    "\n",
    "    # carAudioVal: np.ndarray\n",
    "    # carLabelsVal: np.ndarray\n",
    "    # carAudioVal, carLabelsVal = load_all_audio(\"carVal\", 0)\n",
    "\n",
    "    # tramAudioVal: np.ndarray\n",
    "    # tram_labelsVal: np.ndarray\n",
    "    # tramAudioVal, tram_labelsVal = load_all_audio(\"tramVal\", 1)\n",
    "\n",
    "    # carAudioVal: np.ndarray = normalize_audio(carAudioVal)\n",
    "    # tramAudioVal: np.ndarray = normalize_audio(tramAudioVal)\n",
    "    # audioSamplesVal: np.ndarray = np.concatenate((carAudioVal, tramAudioVal), axis=0)\n",
    "    # yVal: np.ndarray = np.concatenate((carLabelsVal, tram_labelsVal), axis=0)\n",
    "    # xVal: np.ndarray = extract_features(audioSamplesVal)\n",
    "\n",
    "    # yValPred: np.ndarray = clf.predict(xVal)\n",
    "    # accuracy: float = accuracy_score(yVal, yValPred)\n",
    "    # print(f\"Validation Accuracy: {accuracy}\")\n",
    "    # print(classification_report(yVal, yValPred))\n",
    "\n",
    "    # Test the model\n",
    "    yTestPred: np.ndarray = clf.predict(xTest)\n",
    "    accuracy: float = accuracy_score(yTest, yTestPred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(classification_report(yTest, yTestPred, target_names=[\"Car\", \"Tram\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f71656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Car       1.00      1.00      1.00        11\n",
      "        Tram       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        22\n",
      "   macro avg       1.00      1.00      1.00        22\n",
      "weighted avg       1.00      1.00      1.00        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "dataml100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
